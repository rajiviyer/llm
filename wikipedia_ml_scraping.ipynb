{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d16cc141-45a6-41b5-8f4e-405ae16ce2d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T04:38:01.432103Z",
     "iopub.status.busy": "2024-01-17T04:38:01.431716Z",
     "iopub.status.idle": "2024-01-17T04:38:02.274767Z",
     "shell.execute_reply": "2024-01-17T04:38:02.273614Z",
     "shell.execute_reply.started": "2024-01-17T04:38:01.432055Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pickle\n",
    "from timeit import default_timer as timer\n",
    "import time\n",
    "import pathlib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e804f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96a552d5-e650-45df-ab8b-015cf4ec6e97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T04:26:45.978635Z",
     "iopub.status.busy": "2024-01-17T04:26:45.977562Z",
     "iopub.status.idle": "2024-01-17T04:26:45.984755Z",
     "shell.execute_reply": "2024-01-17T04:26:45.984008Z",
     "shell.execute_reply.started": "2024-01-17T04:26:45.978606Z"
    }
   },
   "outputs": [],
   "source": [
    "main_url = \"https://en.wikipedia.org/wiki\"\n",
    "WIKIPEDIA_API_URL = \"https://en.wikipedia.org/w/api.php\"\n",
    "categories_processed = []\n",
    "ignore_list = [\"Strategic_management\", \"Business_intelligence_organizations\",\n",
    "               \"Analytics_companies\",\n",
    "               \"Financial_analysts\", \"Market_trends\", \"Forecasting_competitions\", \n",
    "               \"Economic_forecasting\", \"Indicators\", \"Medical_monitoring\", \"Forecasting_organizations\",\n",
    "               \"Technology_forecasting\", \"Weather_prediction\", \"Rankings\", \n",
    "               \"Analysis_of_collective_decision-making\", \"Industrial_robotics\", \n",
    "               \"Industrial_engineering\", \"Operations_research_awards\", \"Operations_research_societies\", \n",
    "               \"Management_systems\", \"Multiple-criteria_decision_analysis\", \"Networks\", \n",
    "               \"Network_scientists\", \"Operations_researchers\", \"Survey_methodology\", \"Data_scientists\",\n",
    "               \"Computational_statistics_journals\", \"Statistical_databases\", \"Statistical_software\",\n",
    "               \"Actuarial_science\", \"Choice_modelling\", \"Coding_theory\", \"Information_theorists\",\n",
    "               \"Height\", \"Lists_by_length\", \"Longest_things\", \"Vertical_extent\", \"Vertical_position\",\n",
    "               \"Population_models\", \"Deep_learning_software\", \"Neural_network_software\", \n",
    "               \"Artificial_intelligence_conferences\", \"Signal_processing_conferences\", \n",
    "               \"Data_mining_and_machine_learning_software\", \"Social_network_analysis_software\", \n",
    "               \"Machine_learning_researchers\", \"Natural_language_processing_researchers\"\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f787aab-526f-45c6-8c02-7f63e87c15fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T04:26:48.791276Z",
     "iopub.status.busy": "2024-01-17T04:26:48.790518Z",
     "iopub.status.idle": "2024-01-17T04:26:48.806074Z",
     "shell.execute_reply": "2024-01-17T04:26:48.805427Z",
     "shell.execute_reply.started": "2024-01-17T04:26:48.791241Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_subcategories(category, depth=1):\n",
    "    params = {\n",
    "        'action': 'query',\n",
    "        'format': 'json',\n",
    "        'list': 'categorymembers',\n",
    "        'cmtitle': f'Category:{category}',\n",
    "        'cmlimit': 'max',\n",
    "        'cmtype': 'subcat'\n",
    "    }\n",
    "\n",
    "    subcategories = []\n",
    "    for _ in range(depth):\n",
    "        response = requests.get(WIKIPEDIA_API_URL, params=params)\n",
    "        data = response.json()\n",
    "        subcategories.extend([item['title'][9:] for item in data['query']['categorymembers']])  # Remove \"Category:\" prefix\n",
    "        if 'continue' not in data:\n",
    "            break\n",
    "        params['cmcontinue'] = data['continue']['cmcontinue']\n",
    "\n",
    "    return subcategories\n",
    "\n",
    "def get_page_urls(category, main_url):\n",
    "    params = {\n",
    "        'action': 'query',\n",
    "        'format': 'json',\n",
    "        'list': 'categorymembers',\n",
    "        'cmtitle': f'Category:{category}',\n",
    "        'cmlimit': 'max',\n",
    "        'cmtype': 'page'\n",
    "    }\n",
    "\n",
    "    response = requests.get(WIKIPEDIA_API_URL, params=params)\n",
    "    data = response.json()\n",
    "\n",
    "    return [main_url + \"/\" + item['title'].replace(\" \",\"_\") for item in data['query']['categorymembers']]\n",
    "\n",
    "def build_category_tree(category, depth=1, debug=False):\n",
    "    if (category not in ignore_list) and (category not in categories_processed):\n",
    "        category_tree = {'name': category, 'subcategories': [], 'page_urls': []}\n",
    "        if debug:\n",
    "            print(f\"Categories Processed: {category}\")\n",
    "        categories_processed.append(category)\n",
    "        if depth > 1:\n",
    "            subcategories = get_subcategories(category, depth)\n",
    "            for subcategory in subcategories:\n",
    "                sub_category_tree = build_category_tree(subcategory.replace(\" \",\"_\"), depth - 1, debug)\n",
    "                if sub_category_tree:\n",
    "                    category_tree['subcategories'].append(sub_category_tree)\n",
    "\n",
    "        page_urls = get_page_urls(category, main_url)\n",
    "        category_tree['page_urls'].extend(page_urls)\n",
    "\n",
    "        return category_tree\n",
    "\n",
    "def create_index(category_tree, index=None):\n",
    "    if index is None:\n",
    "        index = {}\n",
    "    index[category_tree['name']] = category_tree\n",
    "\n",
    "    for subcategory_tree in category_tree['subcategories']:\n",
    "        create_index(subcategory_tree, index)\n",
    "\n",
    "    return index\n",
    "\n",
    "def find_category_in_tree(category_tree, target_category):\n",
    "    if category_tree['name'] == target_category:\n",
    "        return category_tree\n",
    "    for subcategory in category_tree['subcategories']:\n",
    "        result = find_category_in_tree(subcategory, target_category)\n",
    "        if result:\n",
    "            return result\n",
    "    return None\n",
    "\n",
    "def print_category_tree(category_tree, depth=0):\n",
    "    indent = '  ' * depth\n",
    "    print(f\"{indent}{category_tree['name']}\")\n",
    "\n",
    "    for subcategory in category_tree['subcategories']:\n",
    "        print_category_tree(subcategory, depth + 1)\n",
    "\n",
    "    for page_url in category_tree['page_urls']:\n",
    "        print(f\"{indent}  - {page_url}\")\n",
    "        \n",
    "def debug_category(category):\n",
    "    depth = 10\n",
    "    category_tree = build_category_tree(category, depth, debug = True)\n",
    "    \n",
    "def retrieve_all_urls(category_tree):\n",
    "    all_urls = category_tree['page_urls']\n",
    "    for subcategory_tree in category_tree['subcategories']:\n",
    "        all_urls.extend(retrieve_all_urls(subcategory_tree))\n",
    "    return all_urls    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b841199b-5e11-4d41-8b26-99c86fb4ffdc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-16T09:12:10.890938Z",
     "iopub.status.busy": "2024-01-16T09:12:10.890606Z",
     "iopub.status.idle": "2024-01-16T09:14:30.584787Z",
     "shell.execute_reply": "2024-01-16T09:14:30.583693Z",
     "shell.execute_reply.started": "2024-01-16T09:12:10.890910Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping time for Category:Categorical_data = 3.686 seconds\n",
      "Scraping time for Category:Decision_theory = 30.094 seconds\n",
      "Scraping time for Category:Machine_learning = 7.571 seconds\n",
      "Scraping time for Category:Statistical_methods = 33.840 seconds\n",
      "Scraping time for Category:Statistical_theory = 39.475 seconds\n"
     ]
    }
   ],
   "source": [
    "categories = [\n",
    "'Categorical_data',\n",
    "'Decision_theory',\n",
    "'Machine_learning',\n",
    "'Statistical_methods',\n",
    "'Statistical_theory'\n",
    "]\n",
    "\n",
    "depth = 10\n",
    "\n",
    "files = [str(f) for f in pathlib.Path().glob(\"./data/*.pkl\")]\n",
    "\n",
    "categories_processed = []\n",
    "\n",
    "for category in categories:\n",
    "    try:\n",
    "        dump_file_name = f\"{category}.pkl\"\n",
    "        if (not files) or (dump_file_name not in files):\n",
    "            start_time = timer()\n",
    "              # Specify the depth of subcategories to explore\n",
    "            category_tree = build_category_tree(category, depth)\n",
    "            with open(\"./data/\" + dump_file_name,\"wb\") as file:\n",
    "                pickle.dump(category_tree, file)\n",
    "            end_time = timer()\n",
    "            print(f\"Scraping time for Category:{category} = {(end_time - start_time):0.3f} seconds\")\n",
    "            #category_index = create_index(category_tree)\n",
    "            #print_category_tree(category_tree)\n",
    "            time.sleep(5)\n",
    "    except Exception as e:\n",
    "        print(f\"Exception in Retrieving details for Category: {category}, Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20e960ca-7aa3-4818-bc11-37badbf67f0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T04:44:49.919109Z",
     "iopub.status.busy": "2024-01-17T04:44:49.918714Z",
     "iopub.status.idle": "2024-01-17T04:44:49.935582Z",
     "shell.execute_reply": "2024-01-17T04:44:49.934754Z",
     "shell.execute_reply.started": "2024-01-17T04:44:49.919067Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read the category pkl files and extract urls from each\n",
    "files = [str(f) for f in pathlib.Path().glob(\"./data/*.pkl\")]\n",
    "urls = []\n",
    "for cat_file in files:\n",
    "    with open(cat_file,\"rb\") as file:\n",
    "        cat_tree = pickle.load(file)\n",
    "    urls.extend(list(set(retrieve_all_urls(cat_tree))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97df4ac3-2228-4542-af21-2cc82d60d841",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T04:58:53.108226Z",
     "iopub.status.busy": "2024-01-17T04:58:53.107131Z",
     "iopub.status.idle": "2024-01-17T04:58:54.925009Z",
     "shell.execute_reply": "2024-01-17T04:58:54.923866Z",
     "shell.execute_reply.started": "2024-01-17T04:58:53.108196Z"
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve unique urls from the extracted list\n",
    "final_urls = []\n",
    "for url in urls:\n",
    "    if url not in final_urls:\n",
    "        final_urls.append(url)\n",
    "\n",
    "final_urls_df = pd.DataFrame(final_urls, columns= [\"url\"])\n",
    "final_urls_df.to_csv(\"./data/final_urls.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86a23561-74dc-4cbe-b891-de80e1859a25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T05:01:52.386028Z",
     "iopub.status.busy": "2024-01-17T05:01:52.385602Z",
     "iopub.status.idle": "2024-01-17T05:01:52.420337Z",
     "shell.execute_reply": "2024-01-17T05:01:52.419439Z",
     "shell.execute_reply.started": "2024-01-17T05:01:52.385993Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            url\n",
      "0                                         https://en.wikipedia.org/wiki/Neuroph\n",
      "1                                         https://en.wikipedia.org/wiki/Craiyon\n",
      "2      https://en.wikipedia.org/wiki/Chi-square_automatic_interaction_detection\n",
      "3                        https://en.wikipedia.org/wiki/Recursive_neural_network\n",
      "4                          https://en.wikipedia.org/wiki/Support_vector_machine\n",
      "...                                                                         ...\n",
      "16251                         https://en.wikipedia.org/wiki/Gap_(chart_pattern)\n",
      "16252                                 https://en.wikipedia.org/wiki/Forest_plot\n",
      "16253                                      https://en.wikipedia.org/wiki/Sweave\n",
      "16254                                        https://en.wikipedia.org/wiki/Doji\n",
      "16255                              https://en.wikipedia.org/wiki/Thomas_Kailath\n",
      "\n",
      "[16256 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/final_urls.csv\")\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
